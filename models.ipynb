{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "EPOCHS = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "\n",
    "   def __init__(self):\n",
    "      super(LeNet, self).__init__()\n",
    "      # Definição de cada camada da rede neural como atributo da classe\n",
    "      self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "      self.pool = nn.MaxPool2d(2, 2)\n",
    "      self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "      self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "      self.fc2 = nn.Linear(120, 84)\n",
    "      self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "   def forward(self, x):\n",
    "      # Computação dos passos de uma rede neural até a saída produzida\n",
    "      x = self.pool(F.relu(self.conv1(x)))\n",
    "      x = self.pool(F.relu(self.conv2(x)))\n",
    "      x = x.view(-1, 16 * 4 * 4)\n",
    "      x = F.relu(self.fc1(x))\n",
    "      x = F.relu(self.fc2(x))\n",
    "      x = self.fc3(x)\n",
    "      return x\n",
    "\n",
    "   def num_flat_features(self, x):\n",
    "      size = x.size()[1:]\n",
    "      return np.prod(size)\n",
    "   \n",
    "model = LeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "training_set = torchvision.datasets.FashionMNIST(\n",
    "    './data', train=True, transform=transform, download=True)\n",
    "validation_set = torchvision.datasets.FashionMNIST(\n",
    "    './data', train=False, transform=transform, download=True)\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    validation_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 3, kernel_size=3)\n",
    "        self.fc = nn.Linear(192, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 3))\n",
    "        x = x.view(-1, 192)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "training_set = torchvision.datasets.FashionMNIST(\n",
    "    './data', train=True, transform=transform, download=True)\n",
    "validation_set = torchvision.datasets.FashionMNIST(\n",
    "    './data', train=False, transform=transform, download=True)\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    validation_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CustomCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "   def __init__(self):\n",
    "      super(CustomCNN, self).__init__()\n",
    "      # 2 camada convolucionais, 1 camada de pooing e 1 camada linear\n",
    "      self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=(5,5))\n",
    "      self.batchN1 = nn.BatchNorm2d(num_features=6)\n",
    "      self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=(5,5))\n",
    "      self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "      self.batchN2 = nn.BatchNorm1d(num_features=120)\n",
    "      self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "      self.out = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "   def forward(self, t):\n",
    "      # hidden conv layer \n",
    "      t = self.conv1(t)\n",
    "      t = F.max_pool2d(input=t, kernel_size=2, stride=2)\n",
    "      t = F.relu(t)\n",
    "      t = self.batchN1(t)\n",
    "      \n",
    "      # hidden conv layer\n",
    "      t = self.conv2(t)\n",
    "      t = F.max_pool2d(input=t, kernel_size=2, stride=2)\n",
    "      t = F.relu(t)\n",
    "      \n",
    "      # flatten\n",
    "      t = t.reshape(-1, 12*4*4)\n",
    "      t = self.fc1(t)\n",
    "      t = F.relu(t)\n",
    "      t = self.batchN2(t)\n",
    "      t = self.fc2(t)\n",
    "      t = F.relu(t)\n",
    "      \n",
    "      # output\n",
    "      t = self.out(t)\n",
    "      \n",
    "      return t  \n",
    "   \n",
    "model = CustomCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "    )\n",
    "\n",
    "training_set = torchvision.datasets.MNIST(\n",
    "    './data', train=True, transform=transform, download=True)\n",
    "validation_set = torchvision.datasets.MNIST(\n",
    "    './data', train=False, transform=transform, download=True)\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    validation_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_per_batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, model, training_loader, info_per_batch, loss_fn):\n",
    "   running_loss = 0.\n",
    "   last_loss = 0.\n",
    "   st = time.time()\n",
    "\n",
    "   # Here, we use enumerate(training_loader) instead of\n",
    "   # iter(training_loader) so that we can track the batch\n",
    "   # index and do some intra-epoch reporting\n",
    "   for i, data in enumerate(training_loader):\n",
    "      # Every data instance is an input + label pair\n",
    "      inputs, labels = data\n",
    "\n",
    "      # Zero your gradients for every batch!\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # Make predictions for this batch\n",
    "      outputs = model(inputs)\n",
    "\n",
    "      # Compute the loss and its gradients\n",
    "      loss = loss_fn(outputs, labels)\n",
    "      loss.backward()\n",
    "\n",
    "      # Adjust learning weights\n",
    "      optimizer.step()\n",
    "\n",
    "      # Gather data and report\n",
    "      running_loss += loss.item()\n",
    "      if i % 1000 == 999:\n",
    "         end = time.time()\n",
    "         last_loss = running_loss / 1000  # loss per batch\n",
    "         last_time = (end - st) / 1000  # time per batch\n",
    "         print('batch {} loss: {}'.format(i + 1, last_loss))\n",
    "         running_loss = 0.\n",
    "         \n",
    "         _info_per_batch = {}\n",
    "         _info_per_batch['epoch'] = epoch_index\n",
    "         _info_per_batch['batch'] = i + 1\n",
    "         _info_per_batch['mean_loss'] = last_loss\n",
    "         _info_per_batch['mean_time'] = last_time\n",
    "         _info_per_batch['time_image_batch'] = last_time / BATCH_SIZE\n",
    "         info_per_batch.append(_info_per_batch)\n",
    "\n",
    "         st = time.time()\n",
    "         \n",
    "\n",
    "   return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "batch 1000 loss: 2.0269372535049914\n",
      "batch 2000 loss: 0.8538432704564184\n",
      "batch 3000 loss: 0.7293968826439232\n",
      "batch 4000 loss: 0.6106824914133177\n",
      "batch 5000 loss: 0.5796426721394528\n",
      "batch 6000 loss: 0.5445708718372043\n",
      "batch 7000 loss: 0.5065915509434417\n",
      "batch 8000 loss: 0.467756498349132\n",
      "batch 9000 loss: 0.4955452290140092\n",
      "batch 10000 loss: 0.461220390404691\n",
      "batch 11000 loss: 0.42986467844969595\n",
      "batch 12000 loss: 0.44380887440266087\n",
      "batch 13000 loss: 0.4026490962294047\n",
      "batch 14000 loss: 0.41980449695765854\n",
      "batch 15000 loss: 0.41401716355385726\n",
      "LOSS train 0.41401716355385726 valid 0.42975226044654846\n",
      "[{'epoch': 0, 'batch': 1000, 'mean_loss': 2.0269372535049914, 'mean_time': 0.00681434440612793, 'time_image_batch': 0.0017035861015319825}, {'epoch': 0, 'batch': 2000, 'mean_loss': 0.8538432704564184, 'mean_time': 0.003547818422317505, 'time_image_batch': 0.0008869546055793763}, {'epoch': 0, 'batch': 3000, 'mean_loss': 0.7293968826439232, 'mean_time': 0.00389200496673584, 'time_image_batch': 0.00097300124168396}]\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "   print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "   # Make sure gradient tracking is on, and do a pass over the data\n",
    "   model.train(True)\n",
    "   avg_loss = train_one_epoch(epoch_number + 1, writer)\n",
    "\n",
    "   # We don't need gradients on to do reporting\n",
    "   model.train(False)\n",
    "\n",
    "   running_vloss = 0.0\n",
    "   for i, vdata in enumerate(validation_loader):\n",
    "      vinputs, vlabels = vdata\n",
    "      voutputs = model(vinputs)\n",
    "      vloss = loss_fn(voutputs, vlabels)\n",
    "      running_vloss += vloss\n",
    "\n",
    "   avg_vloss = running_vloss / (i + 1)\n",
    "   print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "\n",
    "   # Salva o melhor modelo\n",
    "   # if avg_vloss < best_vloss:\n",
    "   #    best_vloss = avg_vloss\n",
    "   #    model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "   #    torch.save(model.state_dict(), model_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
